{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idA03vh4y6KN"
      },
      "source": [
        "# Mounting Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExRYQYEHSxPX"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m1gbNl7TROK"
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/Emotion Speech Recognition\"\n",
        "!cd \"/content/drive/My Drive/Emotion Speech Recognition\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5bsxczFB3K1"
      },
      "source": [
        "#  Installation of Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJidbiawsKqA"
      },
      "source": [
        "\n",
        "Essential requirement of of our project :\n",
        "1. **Python 3.7**\n",
        "2. **Librosa**\n",
        "3. **PyTorch**\n",
        "4. **Keras**\n",
        "5. **GPU**\n",
        "\n",
        "We have Already installed this frameworks and packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJfkWa0skV24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4af6fb8-fc09-4c7f-ac84-8f320258793e"
      },
      "source": [
        "# Provides a way of using operating system dependent functionality. \n",
        "import os\n",
        "\n",
        "# LibROSA provides the audio analysis\n",
        "import librosa\n",
        "# Need to implictly import from librosa\n",
        "import librosa.display\n",
        "\n",
        "# Import the audio playback widget\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Image\n",
        "\n",
        "# Enable plot in the notebook\n",
        "%pylab inline\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# These are generally useful to have around\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# To build Neural Network and Create desired Model\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D #, AveragePooling1D\n",
        "from keras.layers import Flatten, Dropout, Activation # Input, \n",
        "from keras.layers import Dense #, Embedding\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne3rYKt-rCyY"
      },
      "source": [
        "# 3. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXKUj7Gg_xbP"
      },
      "source": [
        "\n",
        "### Plotting the audio file's waveform and its spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069SV7_b_xbW"
      },
      "source": [
        "data, sampling_rate = librosa.load('/content/drive/My Drive/Emotion Speech Recognition/Dataset/anger/anger016.wav')\n",
        "# To play audio this in the jupyter notebook\n",
        "ipd.Audio('/content/drive/My Drive/Emotion Speech Recognition/Dataset/anger/anger016.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egIHHnC9JXEZ"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7USoyuhJZ-c"
      },
      "source": [
        "sampling_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Lu9GQt_xbg"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbYYBZz4JdQc"
      },
      "source": [
        "### Setup the Basic Paramter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kntSBjOJsSX"
      },
      "source": [
        "dataset_path = os.path.abspath('./Dataset')\n",
        "destination_path = os.path.abspath('./')\n",
        "# To shuffle the dataset instances/records\n",
        "randomize = True\n",
        "# for spliting dataset into training and testing dataset\n",
        "split = 0.8\n",
        "# Number of sample per second e.g. 16KHz\n",
        "sampling_rate = 20000 \n",
        "emotions=[\"anger\",\"disgust\",\"fear\",\"happy\",\"neutral\", \"sad\", \"surprise\"]\n",
        "\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0lmfGqJrUec"
      },
      "source": [
        "### Converting Dataset in CSV format\n",
        "\n",
        "it will cause easy operation on Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkqxPfRAINO6"
      },
      "source": [
        "# loading dataframes using dataset module \n",
        "!cd \"/content/drive/My Drive/Emotion Speech Recognition/utils\"\n",
        "import dataset\n",
        "# To know more about \"create_and_load_meta_csv_df\" function and it's working, go to \"./utils/dataset.py\" script. \n",
        "df, train_df, test_df = dataset.create_and_load_meta_csv_df(dataset_path, destination_path, randomize, split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkSZBQFKXV1U"
      },
      "source": [
        "print('Dataset samples  : ', len(df),\"\\nTraining Samples : \", len(train_df),\"\\ntesting Samples  : \", len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukhWNo5dwpJQ"
      },
      "source": [
        "# 4. Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXmS7R68wv2w"
      },
      "source": [
        "Let's understand what is our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-HYIREWSHNY"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAL9QiMCIPRY"
      },
      "source": [
        "print(\"Actual Audio : \", df['path'][0])\n",
        "print(\"Labels       : \", df['label'][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdScTp-dIOdm"
      },
      "source": [
        "\n",
        "### Labels Assigned for emotions : \n",
        "- 0 : anger\n",
        "- 1 : disgust\n",
        "- 2 : fear\n",
        "- 3 : happy\n",
        "- 4 : neutral \n",
        "- 5 : sad\n",
        "- 6 : surprise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4eYerYHvNnb"
      },
      "source": [
        "unique_labels = train_df.label.unique()\n",
        "unique_labels.sort()\n",
        "print(\"unique labels in Emtion dataset : \")\n",
        "print(*unique_labels, sep=', ')\n",
        "unique_labels_counts = train_df.label.value_counts(sort=False)\n",
        "print(\"\\n\\nCount of unique labels in Emtion dataset : \")\n",
        "print(*unique_labels_counts,sep=', ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPk7q3mSvfdz"
      },
      "source": [
        "# Histogram of the classes\n",
        "plt.bar(unique_labels, unique_labels_counts,align = 'center', width=0.6, color = 'c')\n",
        "plt.xlabel('Number of labels', fontsize=16)\n",
        "plt.xticks(unique_labels)\n",
        "plt.ylabel('Count of each labels', fontsize=16)\n",
        "plt.title('Histogram of the Labels', fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH92RxJOsCfD"
      },
      "source": [
        "# 5. Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwutQfaY_xcK"
      },
      "source": [
        "### Getting the features of audio files using librosa\n",
        "\n",
        "Calculating MFCC, Pitch, magnitude, Chroma features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgTzmZe98C0"
      },
      "source": [
        "Image('./images/feature_plots.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mgOg9iZ_xcL"
      },
      "source": [
        "from utils.feature_extraction import get_features_dataframe\n",
        "from utils.feature_extraction import get_audio_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdXBI64dHp1z"
      },
      "source": [
        "\n",
        "# trainfeatures, trainlabel = get_features_dataframe(train_df, sampling_rate)\n",
        "# testfeatures, testlabel = get_features_dataframe(test_df, sampling_rate)\n",
        "\n",
        "# I have ran above 2 lines and get the featured dataframe. \n",
        "# and store it into pickle file to use it for later purpose.\n",
        "# it take too much time to generate features(around 30-40 minutes).\n",
        "\n",
        "trainfeatures = pd.read_pickle('./features_dataframe/trainfeatures')\n",
        "trainlabel = pd.read_pickle('./features_dataframe/trainlabel')\n",
        "testfeatures = pd.read_pickle('./features_dataframe/testfeatures')\n",
        "testlabel = pd.read_pickle('./features_dataframe/testlabel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQtrVqQaVuvh"
      },
      "source": [
        "trainfeatures.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4rtHWvXHET"
      },
      "source": [
        "trainfeatures = trainfeatures.fillna(0)\n",
        "testfeatures = testfeatures.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpI4SmIa_xd7"
      },
      "source": [
        "# By using .ravel() : Converting 2D to 1D e.g. (512,1) -> (512,). To prevent DataConversionWarning\n",
        "\n",
        "X_train = np.array(trainfeatures)\n",
        "y_train = np.array(trainlabel).ravel()\n",
        "X_test = np.array(testfeatures)\n",
        "y_test = np.array(testlabel).ravel()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlsrszyfmFh1"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0fYed2umEQo"
      },
      "source": [
        "# One-Hot Encoding\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQZFrkI5_xd_"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjBV6h-R_xeK"
      },
      "source": [
        "### Changing dimension for CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYYiAIWr_xeN"
      },
      "source": [
        "x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "x_testcnn= np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzUvaB10irXl"
      },
      "source": [
        "x_traincnn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0uFcWSgsgS4"
      },
      "source": [
        "# 6. Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XriCw6__xee"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(256, 5,padding='same',\n",
        "                 input_shape=(x_traincnn.shape[1],x_traincnn.shape[2])))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhTkoifP_xej"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZDDACxO_xeq"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb-gPJ5WtrL9"
      },
      "source": [
        "# 7. Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S24BSpb4_xew"
      },
      "source": [
        "### Removed the whole training part for avoiding unnecessary long epochs list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3b-F2-2_xex"
      },
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=370, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-R_5MP9uMDL"
      },
      "source": [
        "### Loss Vs Iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyJJGZjg_xe0"
      },
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JsmT76h_xe5"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf2mTXHp_xe6"
      },
      "source": [
        "model_name = 'omar.h5'\n",
        "save_dir = os.path.join(os.getcwd(), 'Trained_Models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzJYF16p_xe9"
      },
      "source": [
        "import json\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czPDwAVq_xfC"
      },
      "source": [
        "### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug4BC85J_xfD"
      },
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./Trained_Models/omar.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJ6y8GrxPd4"
      },
      "source": [
        "# 8. Test Set Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrJCxbuq_xfG"
      },
      "source": [
        "### Predicting emotions on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWv6Amnt_xfG"
      },
      "source": [
        "preds = loaded_model.predict(x_testcnn, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHMmKejO_xfK"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycDtTVQK_xfN"
      },
      "source": [
        "preds1=preds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orw5YaKd_xfP"
      },
      "source": [
        "preds1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cADBzFv0_xfV"
      },
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzXBNNCZ_xfd"
      },
      "source": [
        "predictions = (lb.inverse_transform((abc)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd-SVnzm_xfl"
      },
      "source": [
        "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
        "preddf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1dLnhpW_xfq"
      },
      "source": [
        "actual=y_test.argmax(axis=1)\n",
        "abc123 = actual.astype(int).flatten()\n",
        "actualvalues = (lb.inverse_transform((abc123)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pe-1Vzv_xft"
      },
      "source": [
        "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
        "actualdf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZNx-CUA_xfz"
      },
      "source": [
        "finaldf = actualdf.join(preddf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akjhl2ux_xf4"
      },
      "source": [
        "## Actual v/s Predicted emotions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp86ztHN_xf5"
      },
      "source": [
        "finaldf[130:140]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FidA-G-Z_xf8"
      },
      "source": [
        "finaldf.groupby('actualvalues').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKCZOmr2_xf_"
      },
      "source": [
        "finaldf.groupby('predictedvalues').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3--LUd4_xgL"
      },
      "source": [
        "finaldf.to_csv('Predictions.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2Ek4Dbw_xgP"
      },
      "source": [
        "# 9. Live Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4nWl6oQ_xgR"
      },
      "source": [
        "#### The file 'output10.wav' in the next cell is the file that was recorded live using the code in AudioRecoreder notebook found in the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc3CyPMwEbkm"
      },
      "source": [
        "demo_audio_path = './Dataset/sad/sad001.wav'\n",
        "ipd.Audio('./Dataset/sad/sad001.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkVmzueV0Qxn"
      },
      "source": [
        "demo_mfcc, demo_pitch, demo_mag, demo_chrom = get_audio_features(demo_audio_path,sampling_rate)\n",
        "\n",
        "mfcc = pd.Series(demo_mfcc)\n",
        "pit = pd.Series(demo_pitch)\n",
        "mag = pd.Series(demo_mag)\n",
        "C = pd.Series(demo_chrom)\n",
        "demo_audio_features = pd.concat([mfcc,pit,mag,C],ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhFRbPOV0DLs"
      },
      "source": [
        "demo_audio_features= np.expand_dims(demo_audio_features, axis=0)\n",
        "demo_audio_features= np.expand_dims(demo_audio_features, axis=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaJsH0t62ewo"
      },
      "source": [
        "demo_audio_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luo-nURx_xg8"
      },
      "source": [
        "livepreds = loaded_model.predict(demo_audio_features, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRihVXvI_xg_"
      },
      "source": [
        "livepreds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpTVXEvf4aQg"
      },
      "source": [
        "# emotions=[\"anger\",\"disgust\",\"fear\",\"happy\",\"neutral\", \"sad\", \"surprise\"]\n",
        "index = livepreds.argmax(axis=1).item()\n",
        "index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhpfTtK_xhA"
      },
      "source": [
        "emotions[index]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}